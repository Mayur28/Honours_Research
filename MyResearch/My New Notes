
SPICE EVERYTHING UP, TOO SIMILIAR!!!
Blend it with Mask Shadow GAN
 Find other papers as well
 Do with my own understanding!!!
This is just temporary, be ruthless thereafter

Concrete To Do List
Fix ALL THINGS PATCHES!!!
THOROUGHLY UNDERSTAND THE SWITCHING OF LABELS IN backward_G
Experiment what happens if I also adjust the disc loss where I do not subtract ( generator held up quite well)
# There is a lot of variation that can come out of the VGG functions
 Really make this my own! Experiment and only if really broken, revert to their altered form
 Once everything seems to be working, see if I can form the generator programmatically! #--> I bookmarked the solution
 I particularly need to look into the get_target tensor function. There can be significant improvement
 #Start with the above point tomorrow as it is pertinent!!!
 Try to find a way to plot the loss after every xxx epochs ( Try to link it using tensorboard and try a dummy example on Colab before commiting)
 The handling of the backward functions for the discriminator can be significantly improved!
 Fix the conversion functions ( TensorToImage,etc)... Right now, they are directly copied over!!!
 #(Change the 'help' eventually!)
 # Examine their multiple approaches again and try to combine uniquely
 # They are using maxpooling in the generator, not avg_pooling... Check Radford's approach to downsampling
 # Default setting doesn't use 'lighten' which normalizes the attention map... Experiment with this! Only appears just before
 #the attention map calculation...
 Overhaul the entire structure as if I were starting from scratch
 # Focus on reducing noise!
 Look into optimizing choice of batch size ( this seems very influential)... smaller batches= more significant changes per an update ( this is
 more noisy, though, the noise can help with the model's generalization capabilities)
 Make sure the configuration of the PatchGAN is perfect! ( Structurally)
 Check what exactly is going on in backward_G
Investigate the effect of increasing the number of patches that we extract
Look into better ways of handling the backward functions (particularly the loss function stuff)--> Very messy
Try working with cv2 once more!
Check if eventually decaying the learning rate is really useful or not.



Concrete Investigative list
Look into whether the order of training the generator and the discriminator is correct or not
 Check the story about the transformation needed for preprocessing ( If RGB-> BGR is really necessary)
 Go beyond what I wanted and state how exactly do I want to improve this in the long run
 Check if it is absolutely necessary to have skip connections in the Unet generator
 Try to understand how exactly to maneuver the input tensor (particularly in the get_target tensor function)
 # vgg_choose will be set to relu5_1. Remove the if-statements in networks.py--> Check why was this option used
 # I want tanh at the end of mine!--> Check if this would break the definition of an LSGAN
 # Theres actually a lot that I removed from 'UnalignedDataset' that appears to relate to data augmentation... Experiment with this--> Check if data augmentation is really necessary when we have an abundance of unpaired data to train on!
 # What does the pool_size do and affect results?
 What is the effect of the rate of convergence on the quality of the Output
 I have to thoroughly understand the difference between a normal GAN, using MSE loss and LSGAN( I am using an LSGAN)... Look into
 why this is a good choice!
 Check difference between Variable and Tensor (seems to have something to do with how gradients are calculated but surely tensors are also capable?)
 # Focus on reducing noise!
 Check why is a 13x13 grid produced by the discriminator for each image in the batch
What is ragan? It is used by the global disc when backpropping but not used by the local discriminator
Look into better ways of handling the backward functions (particularly the loss function stuff)--> Very messy
 Why is preprocessing needed for the VGG network to convert from [RGB-->BGR] and [-1,1]-->[0,255]??? Could be with the way the vgg model was trained? There could be a discrepancy
 Check if vgg_mean is actually useful or not? Seems to have potential?
 Look into how vgg and vgg_loss are different... self.vgg_loss.compute_vgg_loss(self.vgg)... vgg_loss is a class and useful and uses the accepts self.vgg as input ... vgg is only the network, nothing else!
 Why was relu5_1 used for the VGG network?
 Investigate thoroughly how is the forward function of the VGG network being called implicitly. Might be that when called, it calls the other function that is not the __init__ function



Other notes
THe PatchGAN structure is perfect!
