MAJOR OVERHAUL NEEDED!!!!

Experimenting with how the attention map is attained
There's seems to be converging much faster than mine
What seems odd is that they divide there greyscale image by 2... Try with halving mine as well... See if I can bias my approach somehow
I think that I should stay away from lr=0.0002, seems to be causing the model to collapse( Verify this soon!)
For any verification, execute "Minor changes to Perfect" from GitHub
It is now verified that it was the 0.0002 lr that caused the weird effects
Look into any potential Perceptual Loss enhancements!
# Check what is the best way to downsample--> EGAN: MaxPool.... I'm following Radford and doing fractionally strided convolution

To Do Today
Sort out upsampling in Generator ( remove there bilinear and conv layer nonsense)

Try looking into instance noise which adds noise to the real and synthetic samples They used additive gaussian noise ... Variance needs to decrease over time
Read EGAN paper and fully understand the gaps ( the equations that dont seem to make sense to me))) Particularly the adv loss and relativistic stuff? --> This may be fairly time consuming!
Fully understand the VGG STUFF
One blog already verifies that we dont have sigmoid at the end of the discriminator ( it says that we need a linear activation--> There exists a built-in called Linear... What is it's purpose?)
Using an L2 loss penalizes and forces the synthetic dist to match the actual distribution instead of just hoping that the discriminator classifies correctly. We work with the distance between the actually distribution and our sythetic distribution
Using the original log loss isn't effective as the discs discriminator is saturating, and since the generator is updated on the discriminators performance, G may not have sufficient information to direct itself towards the true data distribution


LSGAN notes
The blog post is intuitive...
They dont seem to swap the labels for the discriminator, we only do so for the generator ( Compare what is happening here to what EGAN does)
the least squares loss will penalize generated images based on their distance from the decision boundary.
The output layer of the discriminator model must be a linear activation function.
Below is an example configuration from MLM: This involves the use of Convolution-BatchNorm-Activation layer blocks with the use of 2Ã—2 stride for downsampling and transpose convolutional layers for upsampling. LeakyReLU activation layers are used in the discriminator and ReLU activation layers are used in the generator.
Even MLM is truthful for the discriminator and swaps the label for the generator

SPICE EVERYTHING UP, TOO SIMILIAR!!!
 Find other papers as well
 Do with my own understanding!!!
The least square loss function is the L2 loss functions
MLM only mentions a change to the output layer of the discriminator, therefore, I can add in the tanh to the generator's output

Concrete To Do List
Investigate the effect of increasing the number of patches
Implement Data Augmentation! I Can definitely optimize how this is done. Don't even look at their way
Experiment the effect when instance normalization is used
Consider using batch_size=8... Dont be premature in the verdict... Read hardt carefully before making this a pacifier for everything...
 Really make this my own! Experiment and only if really broken, revert to their altered form
 Once everything seems to be working, see if I can form the generator programmatically! #--> I bookmarked the solution ( OR Just create mini modules/ units!)
 I particularly need to look into the get_target tensor function. There can be significant improvement
 #Start with the above point tomorrow as it is pertinent!!!
 Try to find a way to plot the loss after every xxx epochs ( Try to link it using tensorboard and try a dummy example on Colab before commiting)
 The handling of the backward functions for the discriminator can be significantly improved!
 Fix the conversion functions ( TensorToImage,etc)... Right now, they are directly copied over!!!
 #(Change the 'help' eventually!)
 # Examine their multiple approaches again and try to combine uniquely
 # They are using maxpooling in the generator, not avg_pooling... Check Radford's approach to downsampling
 # Default setting doesn't use 'lighten' which normalizes the attention map... Experiment with this! Only appears just before
 #the attention map calculation...
 # Focus on reducing noise!
 Look into optimizing choice of batch size ( this seems very influential)... smaller batches= more significant changes per an update ( this is
 more noisy, though, the noise can help with the model's generalization capabilities)
 Check what exactly is going on in backward_G
Investigate the effect of increasing the number of patches that we extract
Check if eventually decaying the learning rate is really useful or not.



Concrete Investigative list
Investigate how was the low-light images of egan formed? They seem very artificial... An example being 23_2... The sky cant be that dim... In the paper, that mention the 4 sources (2 normal) and 2 HDR sources... INVESTIGATE THIS THOROUGHLY... could help with quality of performance.
When writing the report, explain the effect of varying every single parameter individually!
Experiment the effect when instance normalization is used
Look into whether the order of training the generator and the discriminator is correct or not
 Check the story about the transformation needed for preprocessing ( If RGB-> BGR is really necessary)
 Go beyond what I wanted and state how exactly do I want to improve this in the long run
 Check if it is absolutely necessary to have skip connections in the Unet generator
 Try to understand how exactly to maneuver the input tensor (particularly in the get_target tensor function)
 # vgg_choose will be set to relu5_1. Remove the if-statements in networks.py--> Check why was this option used
 # I want tanh at the end of mine!--> Check if this would break the definition of an LSGAN
 # Theres actually a lot that I removed from 'UnalignedDataset' that appears to relate to data augmentation... Experiment with this--> Check if data augmentation is really necessary when we have an abundance of unpaired data to train on!
 # What does the pool_size do and affect results?
 What is the effect of the rate of convergence on the quality of the Output
 I have to thoroughly understand the difference between a normal GAN, using MSE loss and LSGAN( I am using an LSGAN)... Look into
 why this is a good choice!
 Check difference between Variable and Tensor (seems to have something to do with how gradients are calculated but surely tensors are also capable?)
 # Focus on reducing noise!
 Check why is a 13x13 grid produced by the discriminator for each image in the batch
What is ragan? It is used by the global disc when backpropping but not used by the local discriminator
Look into better ways of handling the backward functions (particularly the loss function stuff)--> Very messy
 Why is preprocessing needed for the VGG network to convert from [RGB-->BGR] and [-1,1]-->[0,255]??? Could be with the way the vgg model was trained? There could be a discrepancy
 Check if vgg_mean is actually useful or not? Seems to have potential?
 Look into how vgg and vgg_loss are different... self.vgg_loss.compute_vgg_loss(self.vgg)... vgg_loss is a class and useful and uses the accepts self.vgg as input ... vgg is only the network, nothing else!
 Why was relu5_1 used for the VGG network?
 Investigate thoroughly how is the forward function of the VGG network being called implicitly. Might be that when called, it calls the other function that is not the __init__ function
 Check if eventually decaying the learning rate is really useful or not.



Other notes
THe PatchGAN structure is perfect!
Note! Increasing from EGAN 6 patches to 8 patches, improvement seems likely but increases the runtime by 4-5 seconds... Dont only focus on runtime and neglect quality of results.... I like the results when 8 patches are used despite the longer runtime... Mention this caveat in the report

From Radford
Replace Maxpooling with spatial convolutions to downsample which allows the network to learn its own spatial downsampling
apparently Above is used in the discriminator as well
Use batch normalization wherever possible, accept for the output layer of the generator and the input layer of the discriminator
Generator uses Relu only ( except output layer which uses tanh). Discriminator uses leaky RELu
For weight initialization, zero mean and std dev=0.02. Leak=0.2
lr=0.0002... 0.5 beta1

Recent analysis has shown that there is a direct link between how fast models learn and their generalization performance (Hardt et al., 2015).
For above, dont get premature with initial results, wait it out.
Surprisingly, Mask shadow GAN obeys alot from Radford but uses Instance norm in both networks



Notes
- From a performance perspective, I am capable of achieving about 76 sec epochs in the bare bones approach, although, performance should'nt be made the only priority... EGAN's default is 87 seconds... Mention the tradeoff of speed and quality
- Note the pattern for the number of filters used in the generator, when downsampling, the number of filters doubles. When upsampling, the number of filters is halved. Additionally, The number of filters is equal in mirrored layers (for example. the first layer has the sample number of filters as the last layer.)
- Very important, we do not perform normalization in the first layer of the generator. (needs to be accounted for seperately, the rest can be produced algorithmically)--> EGAN has an extra layer and does not use normalization which shouldn't primarily determine the performance of the entire algorithm.
- My understanding of EGAN is slightly flawed. I thought EGAN primarily uses instance normalization which isnt the case. Instead, it primarily uses batch norm but uses instance norm before the VGG for stability
- The discriminator is built algorithmically by defining a batch and using it as many times that is specified(n_layers_D)
- The dataloader loads the data into batches ( and pretty much handles all the data handling) by using the GPU. LOOK INTO THE DATALOADER STUFF THOROUGHLY!! To use the dataloader stuff, it is compulsory to implement the __getitem__ and __len__ magic functions
- The 'data' training loop is a dictionary where each element is a tensor (with dimensions 16x3xsizexsize). These tensors represent A,B,input_A_gray and input_imgs. It also stores 'A_paths' which is the path to the training images accessed in that batch. Go deeper into how this dictionary is actually formed using the data loader.
- Remember, single model is the grand network which contains the generator and the discriminator. (we are working with an instance of 'single model'). That is why in 'optimize_parameters', we only calling forward() once which will propagate through the generator and the discriminator.  Note that we are doing the alternating training batches thing as mentioned by Radford.
- The __getitems__ function in unaligned_dataset is called each iteration and is used to form the dictionary form of the batch with the A,B,input image and attention map!
I changed DataParallel (towards the end of the definition of the generator and the discriminator) because at the moment, I'm only using one GPU.This function basically chunks the input across all the GPU's (uncomment if Shun makes a plan)
- When they say that they concatenate and reshaping the attention maps to the filter size, we actually do this in the decoder( get multiplied when we are upsampling)
- When I want to see the latent stuff, the attention map and the patchs, uncomment the original dictionary setting.
- It appears that the output is formed by multiplying the latent image with the low-light image.
- Mask- Shadow GAN has it like original paper (opposite to EGAN) : They put Norm. before Relu????
- The LSGAN can be implemented by using the target values of 1.0 for real and 0.0 for fake images and optimizing the model using the mean squared error (MSE) loss function, e.g. L2 loss. The output layer of the discriminator model must be a linear activation function.
- Check if there is a resize function in single_model.py ( There isn't in the entire project. Note that looking at the base_dataset, it accepts torch.utils.data which is built-in and explicitly specifies that egt_im and len need to be overwritten). the 'resize_' function is a built-in tensor function.
- The type/ form of training data can have a huge impact on what the GAN achieves



Questions
- Where does the perceptual loss fit in?
- I see where we are calculating the attention map but I dont see where are we using it. A) When upsampling in the generator, we are also resizing them to match the feature map sizes.
- Understand how the filters, kernels and strides are configured to achieve different things (In our case, it is just a matter of doubling the number of filters compared to the previous layer and vice versa when upsampling.)
- How are we enforcing that the range of the generator's output is between [-1, 1]?
- Find out the following from Richard: Find out the following: Its usually Conv->Batch-> Relu but here its Conv-> Relu->Batch. Answer! MLM states that this is not an issue. Org. paper has it like normal but experimentation revealed that better perf.
is achieved if placed after the activation layer. If possible, try to test both!
- Why do many of the classes accept a parameter? An example being the unaligned_dataset class in unaligned_dataset.py
- In vgg_preprocess, why are the colour channels reversed?


To Do List
- Mask-Shadow GAN uses tanh on the output of the generator. ( But are they using LSGAN -> yes). Try to include in my implementation?
- Read up on the LSGAN loss! (Read MLM's article on LSGAN
) Very Important!!!
- I MUST BLEND WITH THE PyTorch DCGAN EXAMPLE AND CHECK THE OVERLAPS AND DISPARITIES
- Check what size images we are working with. The paper and dataset reflects 600x400 but the processing seems to account for 320x320

- In the long term, I may need to compile better datasets. I dont think training for the 2 roles simulataneously is a viable solution. FIND A BETTER STRATEGY TO TRAIN FOR THE 2 TASKS

- Try to display the many aspects within the generator when doing a forward pass (what do the many resized attention maps or the latent result look like before any further processing)


- Confirm the story of switching the labels in backward_G!

- Look into the main functions (the arch. of the networks as well as how they forward and back propagate)
- Confirm the switching of labels in the backward_G function
- It appears that the output is formed by multiplying the latent image with the low-light image. (Verify this!)
- READ ENLIGHTEN
-  GET MY FINAL VERSION OF THE CODE READY (WITH ALL THE NECESSARY AMENDMENTS PERFORMED!!!)
- Check what is going on in backward_G as to how the  loss_G_A is computed (why are they switched?)
- Where are acknowledging that skip connections are used, but it doesnt seem as if we are actually including any information in the attention modules(<-- what EGAN calls it)
- Check if I can optimize how VGG can be used!
- Check what is the purpose of the latent result
- I dont see where is the vgg forward function called? In the Perceptual loss class, I see that we are using the vgg network but I dont see where we explicitly forward propagate. We dont, but investigate how is a result produced if we do not forward propagate
- For some reason, we dont ever set the discriminators to trainable? --> Not neccesary as this is the default

My Experimentations:
- To upsample in the generator, try the transpose convolutional layer
- Check what happens if I remove the resize in the set_input function (single model.py)
- Its okay if our training results seem small because for the prediction process, the original size is maintained.
- Try to filter out line 265 in single_model.py. It seems to me that many aspects are redundant.
- Try another form of downsampling in the generator( to remove the maxpooling)
- Since I'm assuming that the model is being trained for even darkness, take matters into my own hands and try with my own images to verify!
-TRY TO PUT THE BATCH NORMALIZATION BEFORE THE LReLu(MLM says before but many forums found empirically that BN after LReLu performs better)
- See what happens if we dont decay the learning rate after 100 epochs
- For my experiment on batch vs instance normalization, there is a dedicated function (nn.InstanceNorm2d(in_features)--> Look into it more!)
-DO NOT MESS WITH THE DISCRIMINATOR, THE DISCRIMINATOR IS THE GOSPEL TRUTH (EGAN AND MSG have the same form of discriminator.)

- (Outcome Pending) It is what it is when I train one after another but tell them its the conflicting between the 2. Its not the architecture since most shadow removals use my architecture. Show when trained seperately and bring it to Hairong's attention. She said herself to train sequentially!
- I see that they are using maxpooling, I should see if I can instead use the transpose_conv to down sample(This move is backed by Radford)

Notes for the Report:
- For the report, I should definitely include a diagram of the architecture since she specifically asked for it ( but it needs to be indistinguishable from Enlighten-GAN!)
- (Outcome pending on this) In my report, I should show off that I dont need anything too dramatic for shadow detection (like ST-CGAN that dedicates an entire GAN for it)
- (Outcome pending) Find a way to do erosion and dilation to the attention map. Try doing these operations before adding to tensor but the noise removal will probably be expensive.
- When writing the report, describe how the data is pre-processed!
- In my write-up make sure I mention that Im using LSGAN loss and explain it. In the discriminator, instead of just being right or wrong, it tells how right or wrong we are.
- Find a way to remove the noise
- Be absolutely precise when it comes to detail, for example, when discussing the dataset, go into detail of where the images came from, what do they contain, what is it's form(png and size), why did I use it... Were they preprocessed
