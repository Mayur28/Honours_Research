I'm trying without handling the image path! Looks like this will need special attention when saving the images( This will come much later)
SPICE EVERYTHING UP, TOO SIMILIAR!!!
Blend it with Mask Shadow GAN
 Find other papers as well
 Do with my own understanding!!!
This is just temporary, be ruthless thereafter

 Check the story about the transformation needed for preprocessing ( If RGB-> BGR is really necessary)
 I AM working directly in BGR, only when saving for display images, save the image in RGB
 
 Check if the config thing in EGAN is really necessary or not.
 
 # There is a lot of varitation that can come out of the VGG functions
 Really make this my own! Experiment and only if really broken, revert to their altered form
 
 Once everything seems to be working, see if I can form the generator programmatically! #--> I bookmarked the solution
 
 A lot of the variation will also come from the generator's and discriminator's setup
 
 Between adjusting the dataset and removing the config, we're doing fewer 'iterations' per an epoch but this hasn't affected the quality of performance ( also reduced the time to 78-80 sec)
 
 Look at the alternate configurations of EGAN and experiment
 
 Go beyond what I wanted and state how exactly do I want to improve this in the long run
 
 Check if it is absolutely necessary to have skip connections in the Unet generator
 
 Check what does the super thing mean
 
 Try to understand how exactly to manourvre the input tensor (particularly in the get_target tensor function)
#Start with the above point tomorrow as it is pertinent!!!
 
 
 Try to find a way to plot the loss after every xxx epochs
 
 I particularly need to look into the get_target tensor function. There can be significant improvement
 
 The handling of the backward functions for the discriminator can be significantly improved!
